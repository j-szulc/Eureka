{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a7df34-70dd-4f98-bced-4cb3239f0d76",
   "metadata": {},
   "source": [
    "## Setup:\n",
    "\n",
    "Run `bash install.sh` inside `/notebooks/installation/` and just accept everything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a4e68-1ad6-48b0-b68d-c33020478e72",
   "metadata": {},
   "source": [
    "## \"Proof\" that IsaacGymEnv works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55a1e3d0-e5a8-4fab-819f-84ecd904cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m 'root_prefix' set with default value: /root/micromamba\n",
      "Importing module 'gym_38' (/notebooks/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)\n",
      "Setting GYM_USD_PLUG_INFO_PATH to /notebooks/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 148, in _path_is_mode_type\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 142, in _path_stat\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/root/micromamba/envs/eureka/lib/python3.8/site-packages/torch/utils/__init__.abi3.so'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/notebooks/Eureka/isaacgymenvs/isaacgymenvs/train.py\", line 39, in <module>\n",
      "    from isaacgymenvs.tasks import isaacgym_task_map\n",
      "  File \"/notebooks/Eureka/isaacgymenvs/isaacgymenvs/tasks/__init__.py\", line 29, in <module>\n",
      "    from .ant import Ant\n",
      "  File \"/notebooks/Eureka/isaacgymenvs/isaacgymenvs/tasks/ant.py\", line 31, in <module>\n",
      "    import torch\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/torch/__init__.py\", line 933, in <module>\n",
      "    from ._tensor import Tensor\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/torch/_tensor.py\", line 12, in <module>\n",
      "    import torch.utils.hooks as hooks\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1407, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1379, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1525, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 156, in _path_isfile\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 148, in _path_is_mode_type\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! cd /tmp && micromamba run -n eureka python -m isaacgymenvs.train task=ShadowHand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca4a45ed-26a9-423e-8395-e822dc9c4532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=***REMOVED***\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=***REMOVED***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2163602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HYDRA_FULL_ERROR=1\n"
     ]
    }
   ],
   "source": [
    "%env HYDRA_FULL_ERROR=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "baded0e0-538c-4d89-9ec3-65ab5d7e2bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m 'root_prefix' set with default value: /root/micromamba\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/config_loader_impl.py\", line 390, in _apply_overrides_to_config\n",
      "    OmegaConf.update(cfg, key, value, merge=True)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/omegaconf.py\", line 741, in update\n",
      "    root.__setattr__(last_key, value)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/dictconfig.py\", line 337, in __setattr__\n",
      "    raise e\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/dictconfig.py\", line 334, in __setattr__\n",
      "    self.__set_impl(key, value)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/dictconfig.py\", line 318, in __set_impl\n",
      "    self._set_item_impl(key, value)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/basecontainer.py\", line 549, in _set_item_impl\n",
      "    self._validate_set(key, value)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/dictconfig.py\", line 180, in _validate_set\n",
      "    target = self._get_node(key) if key is not None else self\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/dictconfig.py\", line 475, in _get_node\n",
      "    self._validate_get(key)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/dictconfig.py\", line 164, in _validate_get\n",
      "    self._format_and_raise(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/base.py\", line 231, in _format_and_raise\n",
      "    format_and_raise(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/_utils.py\", line 899, in format_and_raise\n",
      "    _raise(ex, cause)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/omegaconf/_utils.py\", line 797, in _raise\n",
      "    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\n",
      "omegaconf.errors.ConfigAttributeError: Key 'multigpu' is not in struct\n",
      "    full_key: multigpu\n",
      "    object_type=dict\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/notebooks/Eureka/eureka/eureka.py\", line 418, in <module>\n",
      "    main()\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
      "    raise ex\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/hydra.py\", line 105, in run\n",
      "    cfg = self.compose_config(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/hydra.py\", line 594, in compose_config\n",
      "    cfg = self.config_loader.load_configuration(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/config_loader_impl.py\", line 142, in load_configuration\n",
      "    return self._load_configuration_impl(\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/config_loader_impl.py\", line 276, in _load_configuration_impl\n",
      "    ConfigLoaderImpl._apply_overrides_to_config(config_overrides, cfg)\n",
      "  File \"/root/micromamba/envs/eureka/lib/python3.8/site-packages/hydra/_internal/config_loader_impl.py\", line 392, in _apply_overrides_to_config\n",
      "    raise ConfigCompositionException(\n",
      "hydra.errors.ConfigCompositionException: Could not override 'multigpu'.\n",
      "To append to your config use +multigpu=True\n"
     ]
    }
   ],
   "source": [
    "cd ~/Eureka_original/eureka && micromamba run -n eureka python ~/Eureka_original/eureka/eureka.py env=shadow_hand sample=16 max_iterations=3000 iteration=5 num_eval=5 model=gpt-3.5-turbo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /notebooks/Eureka/eureka/outputs/eureka/2024-07-03_17-22-52/policy-2024-07-03_17-22-59/runs/ShadowHandGPT-2024-07-03_17-23-00/nn/last_ShadowHandGPT_ep_5.pth /tmp/shadow_hand.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ae3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9fb41-d8d7-4998-ba6b-e7eb28e11024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShadowHandGPT-2024-07-03_17-00-03\n"
     ]
    }
   ],
   "source": [
    "# !ls \"/notebooks/Eureka/eureka/outputs/eureka/2024-07-03_16-58-25/policy-2024-07-03_17-00-03/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64f270c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/Eureka/eureka/outputs/eureka/2024-07-03_19-52-01/policy-2024-07-03_19-52-40/runs/ShadowHandGPT-2024-07-03_19-52-41/summaries/../nn/last_ShadowHandGPT_ep_5.pth\n"
     ]
    }
   ],
   "source": [
    "!ls /notebooks/Eureka/eureka/outputs/eureka/2024-07-03_19-52-01/policy-2024-07-03_19-52-40/runs/ShadowHandGPT-2024-07-03_19-52-41/summaries/../nn/last_ShadowHandGPT_ep_5.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ae6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
